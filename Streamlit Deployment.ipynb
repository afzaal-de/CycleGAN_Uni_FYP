{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbaeb57-23e5-4360-a76b-a460c9429505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Imagetoimagetranlator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Imagetoimagetranlator.py\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def transform_image(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return transform(image).unsqueeze(0)\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def load_models():\n",
    "    generator_G = torch.load('generator_G.pth', map_location=torch.device('cpu'))\n",
    "    generator_F = torch.load('generator_F.pth', map_location=torch.device('cpu'))\n",
    "    discriminator_G = torch.load('discriminator_G.pth', map_location=torch.device('cpu'))\n",
    "    discriminator_F = torch.load('discriminator_F.pth', map_location=torch.device('cpu'))\n",
    "    return generator_G, generator_F, discriminator_G, discriminator_F\n",
    "\n",
    "generator_G, generator_F, discriminator_G, discriminator_F = load_models()\n",
    "st.title('CycleGAN Image to Image Translation')\n",
    "st.write('Upload an ultrasound image and a breast piece image of chicken for processing with CycleGAN.')\n",
    "ultrasound_image = st.file_uploader('Upload Ultrasound Image', type=['png', 'jpg', 'jpeg'])\n",
    "chicken_image = st.file_uploader('Upload Chicken Image', type=['png', 'jpg', 'jpeg'])\n",
    "\n",
    "if ultrasound_image and chicken_image:\n",
    "    ultrasound_pil = Image.open(ultrasound_image).convert('RGB')\n",
    "    chicken_pil = Image.open(chicken_image).convert('RGB')\n",
    "    st.image(ultrasound_pil, caption='Uploaded Ultrasound Image', use_column_width=True)\n",
    "    st.image(chicken_pil, caption='Uploaded Chicken Breast Image', use_column_width=True)\n",
    "    ultrasound_tensor = transform_image(ultrasound_pil)\n",
    "    chicken_tensor = transform_image(chicken_pil)\n",
    "    with torch.no_grad():\n",
    "        fake_chicken = generator_G(ultrasound_tensor).squeeze().numpy().transpose(1, 2, 0)\n",
    "        fake_ultrasound = generator_F(chicken_tensor).squeeze().numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    def postprocess(tensor):\n",
    "        tensor = tensor * 0.5 + 0.5\n",
    "        tensor = np.clip(tensor * 255, 0, 255).astype(np.uint8)\n",
    "        return Image.fromarray(tensor)\n",
    "\n",
    "    fake_chicken_image = postprocess(fake_chicken)\n",
    "    fake_ultrasound_image = postprocess(fake_ultrasound)\n",
    "        col1, col2, col3 = st.columns(3)\n",
    "        with col1:\n",
    "            st.image(ultrasound_image, caption='Uploaded Ultrasound Image', use_column_width=True)\n",
    "        with col3:\n",
    "            st.image(result_image_display, caption='Processed Result Image', use_column_width=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b305a2-fa8b-41d9-9eb9-a0e631b308c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run Imagetoimagetranslator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55a696-cce8-445d-99e9-82d2ee7e6497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
